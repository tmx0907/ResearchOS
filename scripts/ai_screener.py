#!/usr/bin/env python3
"""
AI ìŠ¤í¬ë¦¬ë‹ â€” Scopus/DB export CSVë¥¼ ì½ì–´ì„œ ê´€ë ¨ ë…¼ë¬¸ë§Œ í•„í„°ë§

ì‚¬ìš©ë²•:
  python3 ai_screener.py ~/ResearchOS/00_search_design/scopus_exports/export.csv
  python3 ai_screener.py export.csv --write     # ê²°ê³¼ ì €ì¥
"""

import csv
import json
import os
import sys
import re
import time
from pathlib import Path
from datetime import datetime
from dotenv import load_dotenv

load_dotenv(Path.home() / "ResearchOS" / "secrets" / ".env")

RESEARCH_PROFILE = Path.home() / "ResearchOS" / "MY_RESEARCH.md"
OUTPUT_DIR = Path.home() / "ResearchOS" / "00_search_design"
LLM_PROVIDER = os.getenv("LLM_PROVIDER", "claude").lower()
DEFAULT_KEYWORDS = [
    "anxiety", "depression", "mood", "mental health",
    "art therapy", "creative", "meaning", "purpose",
    "identity", "automation", "artificial intelligence",
]

def call_llm(prompt, system_prompt):
    if LLM_PROVIDER == "claude":
        from anthropic import Anthropic
        client = Anthropic()
        response = client.messages.create(
            model="claude-sonnet-4-20250514", max_tokens=2000,
            system=system_prompt,
            messages=[{"role": "user", "content": prompt}]
        )
        return response.content[0].text
    else:
        from openai import OpenAI
        client = OpenAI()
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role":"system","content":system_prompt},{"role":"user","content":prompt}],
            temperature=0.2, max_tokens=2000
        )
        return response.choices[0].message.content

def llm_sdk_available():
    if LLM_PROVIDER == "claude":
        try:
            import anthropic  # noqa: F401
            return True
        except ImportError:
            return False
    try:
        import openai  # noqa: F401
        return True
    except ImportError:
        return False

def extract_profile_keywords(research_profile):
    kws = set(DEFAULT_KEYWORDS)
    for line in research_profile.lower().splitlines():
        line = line.strip()
        if line.startswith("- "):
            for token in re.split(r"[,/â†’()\\-]+", line[2:]):
                token = token.strip()
                if len(token) > 2 and re.search(r"[a-z]", token):
                    kws.add(token)
    return sorted(kws)

def rule_based_screen(papers_batch, research_profile):
    keywords = extract_profile_keywords(research_profile)
    results = []
    for i, p in enumerate(papers_batch, 1):
        title = p.get("title", "").lower()
        abstract = p.get("abstract", "").lower()
        content = f"{title} {abstract}"
        hits = sum(1 for kw in keywords if kw in content)

        if hits >= 6:
            rel = "high"
        elif hits >= 3:
            rel = "medium"
        elif hits >= 1:
            rel = "low"
        else:
            rel = "irrelevant"

        counter_terms = ["no effect", "null finding", "not significant", "ineffective", "mixed evidence"]
        is_counter = any(t in content for t in counter_terms)

        if any(t in content for t in ["art", "creative", "music", "therapy"]):
            section = "ì˜ˆìˆ /ì •ì‹ ê±´ê°•"
        elif any(t in content for t in ["ai", "automation", "unemployment", "purpose", "meaning"]):
            section = "AI/ì‹¤ì¡´"
        elif any(t in content for t in ["anxiety", "depression", "cbt", "mindfulness"]):
            section = "ìš°ìš¸/ë¶ˆì•ˆ"
        else:
            section = "êµì°¨ì "

        results.append(
            {
                "index": i,
                "relevance": rel,
                "reason": f"í‚¤ì›Œë“œ ë§¤ì¹­ {hits}ê°œ ê¸°ë°˜ ë£°ë² ì´ìŠ¤ ë¶„ë¥˜",
                "section_fit": section,
                "is_counterargument": is_counter,
            }
        )
    return results

def load_csv(csv_path):
    """Scopus/DB export CSV ì½ê¸°"""
    papers = []
    
    with open(csv_path, 'r', encoding='utf-8-sig') as f:
        reader = csv.DictReader(f)
        for row in reader:
            # Scopus í˜•ì‹: Title, Authors, Abstract, Year, Source title, DOI
            # ë‹¤ë¥¸ DBë„ ë¹„ìŠ·í•œ í•„ë“œë¥¼ ê°€ì§
            paper = {
                'title': row.get('Title', row.get('title', row.get('TI', ''))),
                'authors': row.get('Authors', row.get('authors', row.get('AU', ''))),
                'abstract': row.get('Abstract', row.get('abstract', row.get('AB', ''))),
                'year': row.get('Year', row.get('year', row.get('PY', ''))),
                'journal': row.get('Source title', row.get('journal', row.get('SO', ''))),
                'doi': row.get('DOI', row.get('doi', row.get('DI', ''))),
            }
            if paper['title']:  # ì œëª©ì´ ìˆëŠ” ê²ƒë§Œ
                papers.append(paper)
    
    return papers

def screen_batch(papers_batch, research_profile, use_llm=True):
    """ë…¼ë¬¸ ë°°ì¹˜ë¥¼ AIë¡œ ìŠ¤í¬ë¦¬ë‹"""
    if not use_llm:
        return rule_based_screen(papers_batch, research_profile)
    
    papers_text = ""
    for i, p in enumerate(papers_batch):
        papers_text += f"\n[{i+1}] {p['title']}\n"
        if p['abstract']:
            papers_text += f"    Abstract: {p['abstract'][:300]}\n"
    
    system_prompt = """You are a research screening assistant for a psychology graduate student.
Evaluate papers for relevance. Respond ONLY with valid JSON. No backticks, no markdown."""

    prompt = f"""ë‚´ ì—°êµ¬ í”„ë¡œí•„:
{research_profile[:2000]}

ì•„ë˜ ë…¼ë¬¸ë“¤ì„ ìŠ¤í¬ë¦¬ë‹í•´ì£¼ì„¸ìš”.
ê° ë…¼ë¬¸ì— ëŒ€í•´ ê´€ë ¨ì„±ì„ íŒë‹¨í•˜ê³  JSONìœ¼ë¡œ ì‘ë‹µ:

{papers_text}

JSON í˜•ì‹ (ë°°ì—´):
[
  {{
    "index": 1,
    "relevance": "high/medium/low/irrelevant",
    "reason": "ê´€ë ¨ ì´ìœ  í•œ ì¤„ (í•œêµ­ì–´)",
    "section_fit": "ì–´ëŠ Lit Review ì„¹ì…˜ì— ë§ëŠ”ì§€ (ì˜ˆ: AI/ì‹¤ì¡´, ìš°ìš¸/ì˜ë¯¸, ì˜ˆìˆ /ì •ì‹ ê±´ê°•, êµì°¨ì )",
    "is_counterargument": false
  }},
  ...
]"""

    try:
        raw = call_llm(prompt, system_prompt)
        cleaned = raw.strip()
        if cleaned.startswith("```"):
            cleaned = re.sub(r'^```\w*\n?', '', cleaned)
            cleaned = re.sub(r'\n?```$', '', cleaned)
        return json.loads(cleaned)
    except Exception:
        return None

def main():
    if len(sys.argv) < 2:
        print("ì‚¬ìš©ë²•: python3 ai_screener.py export.csv [--write]")
        sys.exit(1)
    
    csv_path = Path(sys.argv[1]).expanduser()
    write_mode = '--write' in sys.argv
    
    if not csv_path.exists():
        print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {csv_path}")
        sys.exit(1)
    
    papers = load_csv(csv_path)
    print(f"ğŸ“„ CSVì—ì„œ {len(papers)}í¸ ë¡œë“œ")
    
    research_profile = ""
    if RESEARCH_PROFILE.exists():
        research_profile = RESEARCH_PROFILE.read_text(encoding='utf-8')

    use_llm = llm_sdk_available()
    if not use_llm:
        print(f"âš ï¸ {LLM_PROVIDER} SDK ë¯¸ì„¤ì¹˜: ë£°ë² ì´ìŠ¤ ìŠ¤í¬ë¦¬ë‹ìœ¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
    
    # ë°°ì¹˜ ì²˜ë¦¬ (10ê°œì”©)
    batch_size = 10
    all_results = []
    
    for i in range(0, len(papers), batch_size):
        batch = papers[i:i+batch_size]
        print(f"\nğŸ¤– ìŠ¤í¬ë¦¬ë‹ ì¤‘: {i+1}-{min(i+batch_size, len(papers))} / {len(papers)}")
        
        results = screen_batch(batch, research_profile, use_llm=use_llm)
        
        if results:
            for r in results:
                idx = r.get('index', 0) - 1
                if 0 <= idx < len(batch):
                    batch[idx]['relevance'] = r.get('relevance', 'unknown')
                    batch[idx]['reason'] = r.get('reason', '')
                    batch[idx]['section_fit'] = r.get('section_fit', '')
                    batch[idx]['is_counterargument'] = r.get('is_counterargument', False)
            all_results.extend(batch)
        else:
            print("  âš ï¸  ë°°ì¹˜ íŒŒì‹± ì‹¤íŒ¨")
            all_results.extend(batch)
        
        time.sleep(1)
    
    # ê²°ê³¼ ë¶„ë¥˜
    high = [p for p in all_results if p.get('relevance') == 'high']
    medium = [p for p in all_results if p.get('relevance') == 'medium']
    low = [p for p in all_results if p.get('relevance') == 'low']
    irrelevant = [p for p in all_results if p.get('relevance') == 'irrelevant']
    counter = [p for p in all_results if p.get('is_counterargument')]
    
    print(f"\n{'='*50}")
    print(f"ğŸ“Š ìŠ¤í¬ë¦¬ë‹ ê²°ê³¼:")
    print(f"  ğŸŸ¢ High:       {len(high)}í¸ â†’ Zoteroì— ì¶”ê°€")
    print(f"  ğŸŸ¡ Medium:     {len(medium)}í¸ â†’ ì´ˆë¡ í•œë²ˆ ë” í™•ì¸")
    print(f"  âšª Low:        {len(low)}í¸ â†’ ë‚˜ì¤‘ì— í•„ìš”í•˜ë©´")
    print(f"  âŒ Irrelevant: {len(irrelevant)}í¸ â†’ ë¬´ì‹œ")
    print(f"  âš”ï¸  ë°˜ë¡ :       {len(counter)}í¸ â†’ ë°˜ë“œì‹œ í¬í•¨")
    print(f"{'='*50}")
    
    # ê²°ê³¼ ì €ì¥
    if write_mode:
        # ë§ˆí¬ë‹¤ìš´ ë³´ê³ ì„œ
        lines = []
        lines.append(f"# ğŸ” AI ìŠ¤í¬ë¦¬ë‹ ê²°ê³¼")
        lines.append(f"\n> ì›ë³¸: {csv_path.name}")
        lines.append(f"> ì´ {len(all_results)}í¸ ì¤‘ ê´€ë ¨ {len(high) + len(medium)}í¸")
        lines.append(f"> ë‚ ì§œ: {datetime.now().strftime('%Y-%m-%d %H:%M')}")
        lines.append("")
        
        lines.append("## ğŸŸ¢ High Relevance â€” Zoteroì— ì¶”ê°€í•˜ì„¸ìš”")
        lines.append("")
        for p in high:
            lines.append(f"### {p['title']}")
            lines.append(f"- **Authors:** {p.get('authors', '?')}")
            lines.append(f"- **Year:** {p.get('year', '?')}")
            lines.append(f"- **Journal:** {p.get('journal', '?')}")
            if p.get('doi'):
                lines.append(f"- **DOI:** https://doi.org/{p['doi']}")
            lines.append(f"- **ì´ìœ :** {p.get('reason', '')}")
            lines.append(f"- **ì„¹ì…˜:** {p.get('section_fit', '')}")
            if p.get('is_counterargument'):
                lines.append(f"- âš”ï¸ **ë°˜ë¡  ë…¼ë¬¸**")
            lines.append("")
        
        lines.append("## ğŸŸ¡ Medium Relevance â€” ì´ˆë¡ í™•ì¸ í›„ íŒë‹¨")
        lines.append("")
        for p in medium:
            lines.append(f"- **{p['title']}** ({p.get('year','?')}) â€” {p.get('reason','')}")
        lines.append("")
        
        lines.append("## âš”ï¸ ë°˜ë¡  ë…¼ë¬¸ â€” ë°˜ë“œì‹œ í¬í•¨")
        lines.append("")
        for p in counter:
            lines.append(f"- **{p['title']}** ({p.get('year','?')}) â€” {p.get('reason','')}")
        lines.append("")
        
        output_file = OUTPUT_DIR / f"screening_{datetime.now().strftime('%Y%m%d_%H%M')}.md"
        output_file.write_text('\n'.join(lines), encoding='utf-8')
        print(f"\nğŸ“‹ ê²°ê³¼ ì €ì¥: {output_file}")
        
        # JSONë„ ì €ì¥
        json_file = OUTPUT_DIR / f"screening_{datetime.now().strftime('%Y%m%d_%H%M')}.json"
        json_file.write_text(json.dumps(all_results, ensure_ascii=False, indent=2), encoding='utf-8')
    
    else:
        print(f"\nğŸ’¡ ê²°ê³¼ ì €ì¥: python3 ai_screener.py {csv_path} --write")
    
    print(f"\në‹¤ìŒ ë‹¨ê³„:")
    print(f"  1. ğŸŸ¢ High ë…¼ë¬¸ì„ Zoteroì— ì¶”ê°€")
    print(f"  2. ğŸŸ¡ Medium ì´ˆë¡ í™•ì¸ â†’ í•„ìš”í•œ ê²ƒë§Œ ì¶”ê°€")
    print(f"  3. âš”ï¸ ë°˜ë¡  ë…¼ë¬¸ ë°˜ë“œì‹œ ì¶”ê°€")
    print(f"  4. python3 sync_and_analyze.py --write  (ì¹´ë“œ ìƒì„±)")

if __name__ == '__main__':
    main()
