#!/usr/bin/env python3
"""ResearchOS ì¹´ë“œ ì¸ë±ìŠ¤ ìƒì„±ê¸°."""

from __future__ import annotations

from collections import defaultdict
from datetime import datetime
from pathlib import Path

CARDS_DIR = Path.home() / "ResearchOS" / "02_cards_basic"
BASE_DIR = Path.home() / "ResearchOS"


def parse_frontmatter(path: Path) -> dict:
    content = path.read_text(encoding="utf-8", errors="replace")
    data = {"filename": path.stem, "title": path.stem, "tags": []}

    if not content.startswith("---"):
        return data

    parts = content.split("---", 2)
    if len(parts) < 3:
        return data

    fm_lines = parts[1].splitlines()

    in_tags = False
    for raw in fm_lines:
        line = raw.strip()
        if not line:
            continue

        if line == "tags:":
            in_tags = True
            continue

        if in_tags:
            if line.startswith("- "):
                data["tags"].append(line[2:].strip().strip('"').strip("'"))
                continue
            in_tags = False

        if line.startswith("#") or line.startswith("- "):
            continue

        if ":" in line:
            key, _, value = line.partition(":")
            data[key.strip()] = value.strip().strip('"').strip("'")

    return data


def priority_emoji(priority: str) -> str:
    return {
        "must-read": "ğŸ”´",
        "should-read": "ğŸŸ¡",
        "reference-only": "âšª",
        "to-read": "ğŸ“˜",
    }.get(priority, "ğŸ“˜")


def to_float(value: str | int | float | None) -> float:
    if value is None:
        return 0.0
    try:
        return float(value)
    except (TypeError, ValueError):
        return 0.0


def generate_master_index(cards: list[dict]) -> None:
    lines = [
        f"# ğŸ“š ë§ˆìŠ¤í„° ì¸ë±ìŠ¤ ({len(cards)}í¸)",
        "",
        f"> ì—…ë°ì´íŠ¸: {datetime.now().strftime('%Y-%m-%d %H:%M')}",
        "",
        "| # | P | ì œëª© | ì—°ë„ | ë°©ë²•ë¡  | ê´€ë ¨ì„± |",
        "|---|---|------|------|--------|--------|",
    ]

    for i, card in enumerate(cards, 1):
        title = card.get("title", card["filename"])[:55]
        link = f"[[02_cards_basic/{card['filename']}|{title}]]"
        lines.append(
            f"| {i} | {priority_emoji(card.get('reading_priority', 'to-read'))} | {link} | "
            f"{card.get('year', '?')} | {card.get('method', '?')} | {card.get('relevance_score', '0')} |"
        )

    (BASE_DIR / "INDEX_MASTER.md").write_text("\n".join(lines), encoding="utf-8")


def generate_topic_index(cards: list[dict]) -> None:
    topic_map = defaultdict(list)
    for card in cards:
        for tag in card.get("tags", []):
            if tag.lower().startswith("topic:"):
                topic_map[tag.split(":", 1)[1].strip()].append(card)

    axes = {
        "ğŸ§  Anxiety & Depression": ["anxiety", "depression", "mood", "cbt", "worry", "panic", "gad"],
        "ğŸ¤– AI & Existential": ["ai", "automation", "meaning", "purpose", "identity", "existential", "unemployment"],
        "ğŸ¨ Art & Mental Health": ["art", "therapy", "creative", "music", "expressive", "aesthetic", "flow"],
    }

    lines = ["# ğŸ·ï¸ ì£¼ì œë³„ ì¸ë±ìŠ¤", ""]
    used_topics = set()
    axis_fallback = {axis: [] for axis in axes}

    for axis, keywords in axes.items():
        # No topic tags: infer basic grouping from title/method text.
        for card in cards:
            haystack = " ".join(
                [
                    str(card.get("title", "")).lower(),
                    str(card.get("method", "")).lower(),
                    " ".join([t.lower() for t in card.get("tags", [])]),
                ]
            )
            if any(k in haystack for k in keywords):
                if card not in axis_fallback[axis]:
                    axis_fallback[axis].append(card)

        matches = {
            topic: topic_cards
            for topic, topic_cards in topic_map.items()
            if any(k in topic.lower() for k in keywords)
        }
        if not matches:
            continue

        lines.append(f"## {axis}")
        lines.append("")

        for topic, topic_cards in sorted(matches.items()):
            used_topics.add(topic)
            lines.append(f"### {topic} ({len(topic_cards)}í¸)")
            for card in sorted(topic_cards, key=lambda x: to_float(x.get("relevance_score")), reverse=True):
                lines.append(
                    f"- {priority_emoji(card.get('reading_priority', 'to-read'))} "
                    f"[[02_cards_basic/{card['filename']}|{card.get('title', card['filename'])[:60]}]]"
                )
            lines.append("")

    remaining = {topic: topic_cards for topic, topic_cards in topic_map.items() if topic not in used_topics}
    if remaining:
        lines.append("## ğŸ“‚ Other")
        lines.append("")
        for topic, topic_cards in sorted(remaining.items()):
            lines.append(f"### {topic} ({len(topic_cards)}í¸)")
            for card in sorted(topic_cards, key=lambda x: to_float(x.get("relevance_score")), reverse=True):
                lines.append(f"- [[02_cards_basic/{card['filename']}|{card.get('title', card['filename'])[:60]}]]")
            lines.append("")

    if not topic_map:
        lines.append("## ìë™ ì¶”ë¡  ë¶„ë¥˜ (topic íƒœê·¸ ì—†ìŒ)")
        lines.append("")
        for axis, inferred_cards in axis_fallback.items():
            if not inferred_cards:
                continue
            lines.append(f"### {axis} ({len(inferred_cards)}í¸)")
            for card in sorted(inferred_cards, key=lambda x: to_float(x.get("relevance_score")), reverse=True):
                lines.append(
                    f"- {priority_emoji(card.get('reading_priority', 'to-read'))} "
                    f"[[02_cards_basic/{card['filename']}|{card.get('title', card['filename'])[:60]}]]"
                )
            lines.append("")

    (BASE_DIR / "INDEX_TOPIC.md").write_text("\n".join(lines), encoding="utf-8")


def generate_priority_index(cards: list[dict]) -> None:
    grouped = defaultdict(list)
    for card in cards:
        grouped[card.get("reading_priority", "to-read")].append(card)

    lines = [
        "# ğŸ“– ì½ê¸° ìš°ì„ ìˆœìœ„",
        "",
        "| P | í¸ìˆ˜ |",
        "|--|------|",
        f"| ğŸ”´ Must | {len(grouped.get('must-read', []))} |",
        f"| ğŸŸ¡ Should | {len(grouped.get('should-read', []))} |",
        f"| ğŸ“˜ To-read | {len(grouped.get('to-read', []))} |",
        f"| âšª Ref | {len(grouped.get('reference-only', []))} |",
        "",
    ]

    for priority, emoji, label in [
        ("must-read", "ğŸ”´", "Must-Read"),
        ("should-read", "ğŸŸ¡", "Should-Read"),
        ("to-read", "ğŸ“˜", "To-Read"),
        ("reference-only", "âšª", "Reference-Only"),
    ]:
        items = sorted(grouped.get(priority, []), key=lambda x: to_float(x.get("relevance_score")), reverse=True)
        if not items:
            continue
        lines.append(f"## {emoji} {label}")
        lines.append("")
        for card in items:
            lines.append(
                f"- [ ] [[02_cards_basic/{card['filename']}|{card.get('title', card['filename'])[:60]}]] "
                f"({card.get('year', '?')})"
            )
        lines.append("")

    (BASE_DIR / "INDEX_PRIORITY.md").write_text("\n".join(lines), encoding="utf-8")


def generate_dataview() -> None:
    content = """# ğŸ“Š ë¹„êµ í…Œì´ë¸” (Dataview)

```dataview
TABLE year AS \"Year\", method AS \"Method\", measurement AS \"Tools\", sample_size AS \"N\", effect_size AS \"ES\", reading_priority AS \"P\", relevance_score AS \"Rel\"
FROM \"02_cards_basic\"
SORT relevance_score DESC
```

## ğŸ”´ Must-Read

```dataview
TABLE year AS \"Year\", journal AS \"Journal\", method AS \"Method\"
FROM \"02_cards_basic\"
WHERE reading_priority = \"must-read\"
SORT relevance_score DESC
```
"""
    (BASE_DIR / "COMPARE_DATAVIEW.md").write_text(content, encoding="utf-8")


def main() -> None:
    cards = [parse_frontmatter(path) for path in sorted(CARDS_DIR.glob("*.md"))]

    if not cards:
        print("ì¹´ë“œ ì—†ìŒ")
        return

    cards = sorted(cards, key=lambda x: to_float(x.get("relevance_score")), reverse=True)

    generate_master_index(cards)
    generate_topic_index(cards)
    generate_priority_index(cards)
    generate_dataview()

    print(f"âœ… INDEX_MASTER.md ({len(cards)}í¸)")
    print("âœ… INDEX_TOPIC.md")
    print("âœ… INDEX_PRIORITY.md")
    print("âœ… COMPARE_DATAVIEW.md")


if __name__ == "__main__":
    main()
